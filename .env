# LLM API Configuration
ANTHROPIC_API_KEY=

# Rate Limiting Configuration
RATE_LIMIT=20  # API calls per second
MAX_RETRIES=8  # Maximum number of retry attempts
BACKOFF_MULTIPLIER=2  # Exponential backoff multiplier

# Model Configuration
PLANNING_MODEL=claude-3-5-sonnet-latest  # High-tier model for analysis planning
EXECUTION_MODEL=claude-3-5-haiku-latest  # Lower-tier model for execution
FALLBACK_MODEL=claude-3-5-haiku-latest  # Fallback model for simple tasks

# Analysis Configuration
MIN_CONFIDENCE_SCORE=0.8  # Minimum confidence score for derived compression
MAX_PROMPT_LENGTH=2000  # Maximum length for generated prompts

# GitHub/GitLab Configuration (Optional)
GITHUB_TOKEN=your_github_token_here  # For private GitHub repositories
GITLAB_TOKEN=your_gitlab_token_here  # For private GitLab repositories

# Output Configuration
DEFAULT_FORMAT=xml  # Default output format (xml or json)
DEFAULT_VERBOSE_LEVEL=1  # Default verbosity level (0-3)

# Cache Configuration (Future Use)
# CACHE_ENABLED=true
# CACHE_DIRECTORY=.cache